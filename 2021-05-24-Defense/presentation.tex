% !TEX output_directory=output
\documentclass{beamer}

\usepackage[beamer]{../wjk}

% uncomment to only show notes in PDF
% \setbeameroption{show only notes}

\bibliography{../refs.bib}
\graphicspath{{../graphics/}}

\title[RL for Quantum Control in NMR]{Using Reinforcement Learning for Quantum Control in Magnetic Resonance}
\author[Will Kaufman]{
Will Kaufman\inst{1}
% \and Benjamin Alford\inst{1}
% \and Pai Peng\inst{2} \\
% \and Xiaoyang Huang\inst{2}
% \and Linta Joseph\inst{1}
% \and Paola Cappellaro\inst{2}
% \and Chandrasekhar Ramanathan\inst{1}
}
\date[Spring 2021]{May 24, 2021 \\
% {\footnotesize NSF support under Grants OIA-1921199, PHY1734011, and PHY1915218.}
}
\institute[Dartmouth College]{
\inst{1}Department of Physics and Astronomy, Dartmouth College \\
Hanover, NH 03755, USA
% \and
% \inst{2}Research Laboratory of Electronics, Massachusetts Institute of Technology \\
% Cambridge, Massachusetts 02139, USA
}

\titlegraphic{
\includegraphics[height=.06\textheight]{qisD.png}
\hfill
\includegraphics[height=.06\textheight]{Dartmouth.pdf}
% \hfill
% \includegraphics[height=.06\textheight]{mit_logo.png}
}

\begin{document}

\frame{\titlepage}

% \begin{frame}
% \frametitle{Table of Contents}
% \tableofcontents
% \end{frame}

\section{Spin systems}


\begin{frame}{NMR and spin systems}

Diagram of NMR setup

Description of interactions

\begin{figure}
\centering
\input{../tikz/spin_system.tex}
\end{figure}

\[
    H_{\text{ctrl}}(t) = -B_1(t) \sum_i \gamma_n^i I_x^i -B_2(t) \sum_i \gamma_n^i I_y^i
\]

\note{
Only focusing on closed system dynamics with global control (spins are not addressed individually).
}

\end{frame}


\begin{frame}{Quantum control in spin systems}

Talk about pulses, common errors
% TODO

\begin{figure}
    \centering
    \scalebox{.5}{
    \input{../tikz/rotation-error.tex}
    }
    \hspace{1em}
    \includegraphics[width=.49\textwidth]{phase_transients_viz.png}
    % TODO make this side-by-side and larger
\end{figure}


\end{frame}


\begin{frame}{Magnetic dipolar interactions in solids}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{1H-NMR.jpg}
\hfill
\scalebox{.6}{
\input{../tikz/bath-spins.tex}
}
\end{figure}
\vspace{-1em}
\hspace{3em}
{\scriptsize%
% for NMR spectrum figure
\nocite{Ottowa-NMR}
From Facey 2008.%
}

Magentic dipolar interactions\dots
\begin{itemize}
    \item Broaden spectral lines in NMR (Linta Joseph, J33.00003)
    \item Lead to decay of central spin coherence in bath (Ethan Williams, L29.00010)
\end{itemize}

{\footnotesize
\[
    H_{\text{sys}} = \sum_i \delta_i I_z^i + \sum_{i,j} d_{ij} \left( 3I_z^iI_z^j - \mathbf{I^i} \cdot \mathbf{I^j} \right)
    = H_\text{CS} + H_\text{D}
\]
}

Decoupling dipolar interactions would narrow spectral lines and increase coherence times.


\end{frame}

\section{Hamiltonian engineering}


\begin{frame}{Hamiltonian engineering}

% set up Hamiltonian engineering

\[
H(t) = H_{\text{sys}} + H_{\text{ctrl}}(t)
\]

Goal: ``engineer'' an effective Hamiltonian $H_{\text{eff}}$ using $H_{\text{ctrl}}(t)$

\[
U(T) = Te^{\int_0^T dt -i H t } = e^{-i H_{\text{eff}} T}
\]

% TODO Bloch sphere example showing ideal6 or something for time suspension
\begin{figure}
$H_{\text{eff}} = 0$
\includegraphics[width=.5\textwidth]{hamiltonian_engineering.jpeg}
\end{figure}


\note{
Hamiltonian engineering used for:

\begin{itemize}
    \item Sensing (decoupling dipolar interactions while keeping chemical shift, e.g. $H_\text{eff} = \beta \textcolor[rgb]{0,0.69,0}{H_{\text{CS}}}$)
    \item Quantum memory (decoupling all interactions, $H_\text{eff} = 0$)
    \item Quantum simulation
\end{itemize}
}

\end{frame}



\begin{frame}{Average Hamiltonian theory}

If\dots
\begin{itemize}
    \item Consider cyclic and periodic pulse sequences
    \[
    U_{\text{ctrl}}(t_c) = \identity, H_{\text{ctrl}}(t) = H_{\text{ctrl}}(t + Nt_c)
    \]
    \item Observe system stroboscopically ($t = Nt_c$)
\end{itemize}
\dots then system appears to evolve under an effective \emph{average} Hamiltonian.

\begin{figure}
\centering
\scalebox{.7}{
\input{../tikz/AHT_diagram.tex}
}
\end{figure}
% and include diagram showing difficulty with different time terms

\note{
Average Hamiltonian Theory (AHT) has been used extensively for Hamiltonian engineering. AHT lets you design pulse sequences that decouples (cancels) certain terms in the Hamiltonian.

Axes in the figure show the orientation of the interaction frame, cyclic because first and last orientations are the same.

If you measure at $t_c$, then system will appear to evolve under $\overline{H}$.

% Interaction frame is determined by $H_{\text{ctrl}}$, ``toggles'' the system Hamiltonian.

% Note how the first-order term has commutator of toggled Hamiltonians at different times. This is straightforward to calculate with a 4-pulse sequence, but gets analytically intractable for longer sequences, and for higher-order terms.
}

\end{frame}

\begin{frame}{Existing approaches to Hamiltonian engineering}

\begin{itemize}
    \item WAHUHA 4-pulse sequence (\cite{PhysRevLett.20.180}), decouples dipolar interaction to lowest-order

    \item CORY 48-pulse sequence (\cite{CORY1990205}) designed analytically using AHT to be robust to experimental imperfections, decouples \emph{all} interactions to second order
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{decay_plot.pdf}
\end{figure}

\note{
WHH-4 designed with pen and paper

Plot of average correlation of adamantane sample for FID, and using two pulse sequences. See how coherence time improves with dipolar decoupling! But there's still room to improve before we reach T1 limit.

}

\end{frame}

\begin{frame}{AHT limitations}

{\scriptsize % or \footnotesize
\begin{align*}
    \overline{H}^{(0)} &= \frac{1}{t_c} \int_0^{t_c}
        \widetilde{H}_{\text{sys}}(t) dt \\
    %
    \overline{H}^{(1)} &= \frac{1}{2it_c} \int_0^{t_c} dt_1 \int_0^{t_1} dt_2
        \left[\widetilde{H}_{\text{sys}}(t_1), \widetilde{H}_{\text{sys}}(t_2)\right] \\
    %
    \overline{H}^{(2)} &= -\frac{1}{6t_c}
    \int_0^{t_c} dt_1 \int_0^{t_1} dt_2 \int_0^{t_2} dt_3
    \left\{
    \left[\widetilde{H}_{\text{sys}}(t_1), \left[\widetilde{H}_{\text{sys}}(t_2), \widetilde{H}_{\text{sys}}(t_3)\right]\right] \right. \\
    & \hspace{13em} + \left.
    \left[\left[\widetilde{H}_{\text{sys}}(t_1), \widetilde{H}_{\text{sys}}(t_2)\right], \widetilde{H}_{\text{sys}}(t_3)\right]
    \right\}
\end{align*}
}
\vspace{-1em}
\begin{figure}
\centering
\includegraphics[width=0.3\textwidth]{AHT-HO-diagram.pdf}

{\scriptsize From \cite{brinkmann_2016}.}
\end{figure}
% TODO make sure I can see this figure ^

\note{

AHT is great, but it gets really hard to calculate higher order terms (especially for longer pulse sequences).

``RL has been advancing rapidly in recent years, useful tool for tackling a wide range of problems''

Are there better approaches to Hamiltonian engineering using RL?
}

\end{frame}



\section{Reinforcement learning (RL) for Hamiltonian engineering}

\begin{frame}{Reinforcement learning}

\begin{figure}
\centering
\includegraphics[width=.8\textwidth]{rl.png}

From \cite{sutton2018reinforcement}.
\end{figure}

\begin{figure}
\centering
\includegraphics{tetris.png}
\end{figure}

\end{frame}


\begin{frame}{RL for Hamiltonian engineering}
%

\begin{itemize}
    \item State $\to$ propagator
    \item Action $\to$ control pulse from $\{ D, X, \overline{X}, Y, \overline{Y} \}$
    \item Reward $\to$ propagator fidelity $\left(\Re{
        \frac{\Tr{U_\text{target}^\dagger U(t)}}{\Tr{\identity}}
    }\right)$
    % TODO double check if I'm using this or average gate fidelity
\end{itemize}

Better state representation: sequence of pulses already applied

\note{
With RL, potential for tailored pulse sequences for particular systems (e.g. strongly coupled vs weakly coupled), learned robustness to errors.
}


\end{frame}


\begin{frame}{Constructing pulse sequences using AlphaZero}

Implemented AlphaZero algorithm (\cite{Silver1140}, originally for Chess, Shogi, and Go), though there are many different RL approaches (\cite{peng2021deep}).

\begin{figure}
\centering
\includegraphics[width=.8\textwidth]{az-parallel.jpeg}
\end{figure}

\note{

% TODO continue updating notes here...

Our collaborators at MIT have explored an alternative approach using evolutionary algorithms and deep learning.

% Action space is delay, $\pm$X, $\pm$Y. Target unitary is identity (want no dynamics, refocus/decouple all interactions).

% Each iteration of algorithm involves collecting data in a tree search and training neural networks on the collected data. Neural network maps state to policy (what pulse should I apply next?) and value (how good will this pulse sequence be?).

With tree structure, can optionally add AHT constraints to search.

% Collects data on pulse sequences, balancing \emph{exploration} of new
% pulse sequences and \emph{exploitation} of learnings (via neural
% networks), and trains neural networks on collected data to learn from
% recent experiences.
}

\end{frame}



\begin{frame}{AlphaZero: tree search}
%
\begin{figure}
\centering
\scalebox{.7}{
\input{../tikz/mcts.tex}
}
\end{figure}

% TODO make "animation", walk through carefully how this works
% TODO also talk about adding additional constraints

\end{frame}


\begin{frame}{AlphaZero: network training}


\[
    L(\theta) = (r_i - v_\theta(s_i))^2 - \pi_\theta(s_i) \cdot \log \mathbf{p_i} + c ||\theta||^2
\]

\end{frame}



\begin{frame}{Computational results}

% TODO Sekhar: "You don't have a lot of sequences, I'd consider explicitly listing them here"
% TODO change here... Just list all jobs I ran/have results for

Goal: decouple all interactions (\(\overline{H}=0\)) in strongly coupled spin systems with experimental imperfections.

\begin{itemize}
    \item Consistency checks: $10$ identical runs using same parameters
    \item Unconstrained search (\emph{tabula rasa}, no AHT knowledge), no errors
    \item Constrained tree search with AHT, no errors
    \item Constrained tree search with AHT and $6\tau$ refocusing, no errors
    \item Constrained tree search, simulated errors
\end{itemize}

\note{

}

\end{frame}



\begin{frame}{Consistency check}

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{az-consistency.pdf}
\end{figure}

\note{
$24\tau$ sequence, no errors, AHT0 and 6tau constraints.
}

\end{frame}


\begin{frame}{Unconstrained tree search}
%
\begin{figure}[H]
    \centering
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-no_constraints-12.pdf}
        \caption{$12\tau$ sequence}
        \label{fig:reward_hist-no_errors-no_constraints-12}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-no_constraints-24.pdf}
        \caption{$24\tau$ sequence}
        \label{fig:reward_hist-no_errors-no_constraints-24}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-no_constraints-48.pdf}
        \caption{$48\tau$ sequence}
        \label{fig:reward_hist-no_errors-no_constraints-48}
    \end{subfigure}
\end{figure}

\note{
Distribution of ``rewards'' ($-\log(1 - \text{fidelity})$) during AlphaZero training. No constraints were applied to the tree search, and the simulated spin systems were idealized.
}

\end{frame}





\begin{frame}{Constrained tree search with AHT}
%
\begin{figure}[H]
    \centering
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-AHT0-12.pdf}
        \caption{$12\tau$ sequence}
        \label{fig:reward_hist-no_errors-AHT0-12}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-AHT0-24.pdf}
        \caption{$24\tau$ sequence}
        \label{fig:reward_hist-no_errors-AHT0-24}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-AHT0-48.pdf}
        \caption{$48\tau$ sequence}
        \label{fig:reward_hist-no_errors-AHT0-48}
    \end{subfigure}
\end{figure}

\note{
Distribution of ``rewards'' ($-\log(1 - \text{fidelity})$) during AlphaZero training. Lowest-order AHT constraints were applied to the tree search, and the simulated spin systems were idealized.
}

\end{frame}


\begin{frame}{Constrained tree search with AHT and $6\tau$ refocusing}
%
\begin{figure}[H]
    \centering
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-6tau-12.pdf}
        \caption{$12\tau$ sequence}
        \label{fig:reward_hist-no_errors-6tau-12}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-6tau-24.pdf}
        \caption{$24\tau$ sequence}
        \label{fig:reward_hist-no_errors-6tau-24}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{hists/reward_hist-no_errors-6tau-48.pdf}
        \caption{$48\tau$ sequence}
        \label{fig:reward_hist-no_errors-6tau-48}
    \end{subfigure}
\end{figure}

\note{
Distribution of ``rewards'' ($-\log(1 - \text{fidelity})$) during AlphaZero training. Lowest-order AHT constraints and refocusing all interactions every $6\tau$ were applied to the tree search, and the simulated spin systems were idealized.
}

\end{frame}

\begin{frame}
{Robustness to rotation errors (no errors in training)}

Training policy without any errors leads to terrible pulse sequences!

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{robustness/rot_errors-no_errors.pdf}
\end{figure}

\note{
Robustness against rotation errors, relative to a $\pi/2$-pulse. The pulse sequences identified using AlphaZero have very poor robustness to rotation errors, while the CORY48 sequence (which was designed using AHT to be robust to such errors) has high fidelity for a much broader range of rotation errors.
}

\end{frame}

\begin{frame}{Robustness to phase transient errors  (no errors in training)}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{robustness/phase_transients-no_errors.pdf}
\end{figure}

\end{frame}

\begin{frame}{Robustness to resonance offset errors  (no errors in training)}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{robustness/offset_errors-no_errors.pdf}
\end{figure}

\end{frame}


\begin{frame}{Robustness to rotation errors (errors in training)}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
\end{figure}

\end{frame}

\begin{frame}{Robustness to phase transient errors (errors in training)}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
\end{figure}

\end{frame}

\begin{frame}{Robustness to resonance offset errors (errors in training)}

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{example-image}
\end{figure}

\end{frame}

\begin{frame}{Experimental results}

\begin{figure}
\centering
\includegraphics[width=.9\textwidth]{decay_plot_1.pdf}
\end{figure}

\end{frame}

\begin{frame}{Summary}

\begin{itemize}
    \item Decoupling dipolar interactions is important for narrowing linewidths, increasing coherence times
    \item RL is promising new tool to design new pulse sequences
    \begin{itemize}
        \item Tailored control for specific system characteristics and errors
        \item Best-performing approach likely is a mix of RL and knowledge from AHT
    \end{itemize}
\end{itemize}

\pause

\begin{center}
    Thanks for listening!
\end{center}

\end{frame}


\begin{frame}{Next steps}

\begin{itemize}
    \item Further tune algorithm hyperparameters for consistency, better performance
    \item Add additional constraints on tree search for higher-order terms in average Hamiltonian
\end{itemize}

\end{frame}


\begin{frame}[allowframebreaks]
\frametitle{References}

\printbibliography

\end{frame}
















\section{Appendix}





\begin{frame}{Average Hamiltonian Theory (AHT)}

The time-evolution operator (or propagator) follows the differential
equation \[
i \frac{d}{dt} U(t) = H(t)U(t)
\] \[
U(0) = \identity
\]

The Magnus Expansion gives an exponential solution for the propagator
via an average Hamiltonian \(\overline{H}\) at time \(t\) \[
U(t) = \exp\left( -i \overline{H} t \right)
\] with \(\overline{H} = \overline{H}^0 + \overline{H}^1 + \dots\).

The series converges rapidly when \(t||H|| \ll 1\).

\end{frame}

\begin{frame}{AHT (cont.)}

We often work in the interaction frame of the control Hamiltonian, with transformation operator

\begin{align*}
    \frac{d}{dt} U_{\text{ctrl}}(t) &=
        -i H_{\text{ctrl}}(t)U_{\text{ctrl}}(t) \\
    U_{\text{ctrl}}(0) &= \identity
\end{align*}

So the Hamiltonian in the interaction frame becomes

\[
    \widetilde{H}(t) = \widetilde{H}_{\text{sys}}(t) = U_{\text{ctrl}}(t)^\dagger H_{\text{sys}} U_{\text{ctrl}}(t)
\]

\cite{brinkmann_2016}.
\end{frame}

\begin{frame}{AHT: Pulse sequences}

If a pulse sequence is both cyclic and periodic \cite{gerstein-dybowski}
\begin{align*}
    U_{\text{ctrl}}(t_c) &= T\exp \left(
        -i \int_0^{t_c} H_{\text{ctrl}}(t) dt \right) = \pm \identity
         \, \text{(cyclic)} \\
    H_{\text{ctrl}}(t) &= H_{\text{ctrl}}(t + Nt_c) \, \text{(periodic)}
\end{align*}
then the interaction frame and the lab frame coincide at multiples of
the cycle time, and the propagator can be given by
\[
    U(t_c) = \exp\left( -i t_c (\overline{H}^{(0)} +
        \overline{H}^{(1)} + \dots) \right)
\]
Higher-order terms for average Hamiltonian become nasty\dots

\end{frame}

\begin{frame}{AHT: Special Cases}

\begin{itemize}

\item
  Symmetric pulse sequences (\(H(\tau) = H(t_c - \tau)\)): all odd-order
  terms in average Hamiltonian are zero
\item
  Antisymmetric pulse sequences (\(H(\tau) = - H(t_c - \tau)\)): all
  terms in average Hamiltonian are zero
\end{itemize}
\end{frame}

% \begin{frame}{Spin systems}
%
% % TODO include Hcontrol <-> pulses description
%
% \end{frame}

\begin{frame}{Simulation/RL parameters}

\begin{itemize}
    \item $N=3$ spin-1/2 system, $\delta_i \sim \mathcal{N}(0, 1)$, $d_{ij} \sim \mathcal{N}(0, 100)$
    \item Delay $\tau = 10^{-4}$, pulse length $t_p = 10^{-5}$
    \item Ensemble of 50 spin systems with different chemical shifts and dipolar interactions
\end{itemize}


\begin{itemize}
    \item Replay buffer size: $10^6$ ``experiences'' ($(s, a, r)$)
    \item Batch size: $2048$
    \item Training duration: $10^4$ training steps
\end{itemize}

\[
    \text{fidelity}(U, U_\text{target}) = \Re{
        \frac{\Tr{U_\text{target}^\dagger U(t)}}{\Tr{\identity}}
    }
\]
For RL algorithm performance, use log infidelity as ``reward''
\[
    r = -\log \left( 1 - \text{fidelity} \right)
\]

\[
r = 4 \iff \text{fidelity} = 0.\underline{9999}
\]

% \note{Can apply RL to discrete control problem (pulse sequences)
% or continuous control (shaped pulses, continuously-varying control
% Hamiltonians)}

\end{frame}

\begin{frame}{Computational results: AlphaZero algorithm learns}

\begin{figure}
\centering
\includegraphics[width=.49\textwidth]{az_learning/hist-0000.png}
\includegraphics[width=.49\textwidth]{az_learning/hist-0030.png} \\
\includegraphics[width=.49\textwidth]{az_learning/hist-0090.png}
\includegraphics[width=.49\textwidth]{az_learning/hist-0145.png}
\end{figure}

\end{frame}

\begin{frame}{Comparison between RL approaches}

Different RL algorithm used by our collaborators (\cite{peng2021deep}).

\begin{table}
\centering
\begin{footnotesize}
\begin{tabular}{p{.2\textwidth}|p{.5\textwidth}|p{.25\textwidth}}
    Characteristic & Evolutionary Reinforcement Learning & AlphaZero \\
    \hline
    State representation & Sequence of previous pulses & Same \\
    \hline
    Action space & Delay or $\pi/2$-pulse along $\pm$X, $\pm$Y & Same \\
    \hline
    Learning method & Evolutionary algorithms (gradient-free) & Tree search and experience replay (gradient based) \\
    \hline
    % Neural network architecture  % TODO what is their NN architecture?
    Prior knowledge & Builds longer sequences from shorter ones & Uses AHT to prune tree search \\
    \hline
    Pulse sequences ($H_\text{eff} = 0$) & yxx48 & az48
\end{tabular}
\end{footnotesize}
\end{table}

\end{frame}

\begin{frame}{Neural network structure}

\begin{figure}
\centering
\scalebox{.6}{
\input{../tikz/neural_network.tex}
}
\end{figure}

\end{frame}

\begin{frame}{AlphaZero algorithm}


Explore new pulse sequences

\begin{enumerate}

\item
Start with a zero-length pulse sequence as the root node
\item
With the given root node, perform Monte Carlo Tree Search (MCTS) to
explore potential pulses

MCTS uses a neural network to estimate the prior probabilities for
selecting each pulse and the value (fidelity) for the final pulse
sequence

\item
Sample the next pulse from the root node's children weighted by
their visit counts
\item
Repeat steps 2-4 until a complete pulse sequence is determined
\item
Record the child nodes' visit counts and final pulse sequence
fidelity to a data buffer for training
\end{enumerate}

% TODO clean this slide up!
Parameters for MCTS, training, etc.
\end{frame}

\begin{frame}{AlphaZero algorithm (cont.)}

Train neural networks on collected data

\begin{itemize}

\item
Policy loss: want to minimize the difference between MCTS visit
counts \(\mathbf{p}\) and learned policy \(\pi_\theta\)
\item
Value loss: want to minimize the difference between calculated
fidelity from pulse sequence \(z\) and predicted fidelity from
neural network \(v\)
\item
L2 regularization: prevent overfitting to data
\item
\(l(\theta) = -\mathbf{p} \cdot \log\pi_\theta + (z - v)^2 + c||\theta||^2\)
\end{itemize}
\end{frame}


\begin{frame}{Neural network training}

\includegraphics[width=.49\textwidth]{loss_policy.png}
\includegraphics[width=.49\textwidth]{loss_value.png}
\end{frame}

\begin{frame}{Training performance}

\includegraphics[width=.8\textwidth]{training_fidelity.png}
\end{frame}

\begin{frame}{Pulse sequences identified using AlphaZero}

\textrm{az48} pulse sequence (decouple all interactions):

$ -X, \tau, Y, \tau, Y, \tau, X, \tau, Y, \tau, Y, \tau $
$ -Y, \tau, X, \tau, X, \tau, -Y, \tau, X, \tau, X, \tau $
$ Y, \tau, X, \tau, X, \tau, -Y, \tau, X, \tau, X, \tau $
$ -Y, \tau, X, \tau, -Y, \tau, X, \tau, X, \tau, -Y, \tau $
$ -X, \tau, -X, \tau, Y, \tau, Y, \tau, -X, \tau, Y, \tau $
$ Y, \tau, -Y, \tau, X, \tau, -Y, \tau, -Y, \tau, X, \tau $
$ -Y, \tau, X, \tau, X, \tau, -Y, \tau, X, \tau, X, \tau $
$ -Y, \tau, -X, \tau, -X, \tau, -Y, \tau, -X, \tau, -X, \tau $

\end{frame}

\begin{frame}{RL advantages and disadvantages}

\begin{itemize}
    \item Generalized approach to learning problem: no assumed prior knowledge
    \item Can tailor problem to specific system of interest (e.g. strongly coupled system, timing precision constraints)
    \item Robustness against known errors by including them in simulation of spin system
\end{itemize}

\pause

\begin{itemize}
    \color{red}
    \item Computationally expensive
    \item Poor accuracy of many-body spin simulations
    \item No guarantees for convergence to optimal (or good) solution
\end{itemize}

\end{frame}

\end{document}
