\chapter{Conclusion and Future Work}

% Hamiltonian engineering is important problem
% Existing methods in AHT have been taken to their limit in CORY48
% Need to try different methods to make further improvements

% RL is new tool for control problems

% RL-based pulse sequences work, but aren't state-of-the-art yet
% TODO what's going on?
% sparsity of rewards (only at end of episode, so doesn't get immediate feedback)
% discontinuous reward landscape, sparsity of high rewards (most pulse sequences suck, even when constrained with AHT0)



% next steps
% tune algorithm further (still basically out-of-the-box)
% run for longer, algorithm may just be incredibly computationally intensive?
% think about smarter constraints to tree search
% TODO there's still the policy function, basically unexplored
% could be interesting to see what actions it thinks are useful,
% and see if it reverse-engineers AHT...
